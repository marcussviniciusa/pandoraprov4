import { ChatOpenAI } from "@langchain/openai"
import { ChatGoogleGenerativeAI } from "@langchain/google-genai"
import { ChatAnthropic } from "@langchain/anthropic"
import { HumanMessage, SystemMessage } from "@langchain/core/messages"
import { AIProvider, AIModel, AgentType } from "@/generated/prisma"
import { prisma } from "@/lib/prisma"
import { ToolParser } from "@/lib/ai/tool-parser"
import { WebhookExecutor } from "@/lib/webhook/executor"

export interface AgentConfig {
  id: string
  name: string
  type: AgentType
  prompt: string
  temperature: number
  maxTokens: number
  provider: AIProvider
  aiModel: AIModel
  model: string
}

export interface MessageContext {
  clientPhone: string
  clientName?: string
  conversationHistory: Array<{
    content: string
    isFromClient: boolean
    timestamp: Date
  }>
  currentSpecialty?: string
}

// Mapeamento de modelos para strings dos providers
const MODEL_MAPPING = {
  [AIModel.GPT_4_1_MINI]: "gpt-4.1-mini",
  [AIModel.GPT_4O_MINI]: "gpt-4o-mini", 
  [AIModel.GPT_4_5]: "gpt-4.5",
  [AIModel.GEMINI_2_5_PRO]: "gemini-2.5-pro",
  [AIModel.CLAUDE_3_7]: "claude-3-5-sonnet-20241022",
  [AIModel.CLAUDE_4]: "claude-4-latest"
}

export class MultiProviderAIManager {
  private agents: Map<string, any> = new Map() // eslint-disable-line @typescript-eslint/no-explicit-any
  private providerConfigs: Map<string, Map<AIProvider, string>> = new Map() // officeId -> provider -> apiKey

  constructor() {
    this.initializeAgents()
  }

  private async initializeAgents() {
    try {
      // Buscar todas as configura√ß√µes de providers por escrit√≥rio
      const providerConfigs = await prisma.aIProviderConfig.findMany({
        where: { isActive: true },
        include: { office: true }
      })

      // Organizar configs por escrit√≥rio
      for (const config of providerConfigs) {
        if (!this.providerConfigs.has(config.officeId)) {
          this.providerConfigs.set(config.officeId, new Map())
        }
        this.providerConfigs.get(config.officeId)?.set(config.provider, config.apiKey)
      }

      // Buscar todos os agentes ativos
      const agentConfigs = await prisma.aiAgent.findMany({
        where: { isActive: true },
        include: { office: true }
      })

      // Inicializar cada agente com seu provider espec√≠fico
      for (const config of agentConfigs) {
        const apiKey = this.providerConfigs.get(config.officeId)?.get(config.provider)
        
        if (!apiKey) {
          console.warn(`‚ö†Ô∏è API Key n√£o encontrada para ${config.provider} no escrit√≥rio ${config.office.name}`)
          continue
        }

        const llm = this.createProviderLLM(config.provider, config.aiModel, {
          temperature: config.temperature,
          maxTokens: config.maxTokens,
          apiKey
        })
        
        if (llm) {
          this.agents.set(config.id, llm)
        }
      }

      console.log(`ü§ñ Inicializados ${this.agents.size} agentes de IA com m√∫ltiplos providers`)
    } catch (error) {
      console.error("‚ùå Erro ao inicializar agentes:", error)
    }
  }

  private createProviderLLM(provider: AIProvider, model: AIModel, config: {
    temperature: number
    maxTokens: number
    apiKey: string
  }) {
    const modelString = MODEL_MAPPING[model]

    try {
      switch (provider) {
        case AIProvider.OPENAI:
          return new ChatOpenAI({
            model: modelString,
            temperature: config.temperature,
            maxTokens: config.maxTokens,
            apiKey: config.apiKey,
          })

        case AIProvider.GOOGLE:
          return new ChatGoogleGenerativeAI({
            model: modelString,
            temperature: config.temperature,
            maxOutputTokens: config.maxTokens,
            apiKey: config.apiKey,
          })

        case AIProvider.ANTHROPIC:
          return new ChatAnthropic({
            model: modelString,
            temperature: config.temperature,
            maxTokens: config.maxTokens,
            apiKey: config.apiKey,
          })

        default:
          console.error(`‚ùå Provider n√£o suportado: ${provider}`)
          return null
      }
    } catch (error) {
      console.error(`‚ùå Erro ao criar LLM para ${provider}:`, error)
      return null
    }
  }

  async processMessage(
    agentId: string,
    message: string,
    context: MessageContext,
    conversationId?: string
  ): Promise<{
    response: string
    shouldTransfer: boolean
    suggestedAgent?: AgentType
    suggestedTags: string[]
    provider: AIProvider
    model: AIModel
    toolExecutions?: Array<{
      toolName: string
      executionId: string
      status: string
      message: string
    }>
  }> {
    try {
      // Buscar configura√ß√£o do agente
      const agentConfig = await prisma.aiAgent.findUnique({
        where: { id: agentId },
        include: { office: true }
      })

      if (!agentConfig) {
        throw new Error(`Agente ${agentId} n√£o encontrado`)
      }

      // **NOVA FUNCIONALIDADE: Detectar e executar tools**
      const availableTools = await prisma.tool.findMany({
        where: { 
          officeId: agentConfig.officeId,
          isActive: true 
        }
      })

      const toolCalls = ToolParser.detectToolCalls(message, availableTools)
      let toolResults: string[] = []
      let toolExecutions: Array<{
        toolName: string
        executionId: string
        status: string
        message: string
      }> = []
      
      // Executar tools detectadas
      for (const toolCall of toolCalls) {
        try {
          console.log(`üîß Executando tool: ${toolCall.toolName}`)
          const result = await WebhookExecutor.executeWebhook(
            toolCall.tool, 
            toolCall.description, 
            toolCall.requestId,
            conversationId,
            agentId
          )
          
          toolResults.push(`‚ö° **${toolCall.toolName}**: ${result.message}`)
          toolExecutions.push({
            toolName: toolCall.toolName,
            executionId: result.executionId,
            status: result.success ? 'EXECUTING' : 'ERROR',
            message: result.message
          })

          console.log(`‚úÖ Tool ${toolCall.toolName} executada: ${result.message}`)
        } catch (error: any) {
          const errorMsg = `‚ùå Erro ao executar ${toolCall.toolName}: ${error.message}`
          toolResults.push(errorMsg)
          toolExecutions.push({
            toolName: toolCall.toolName,
            executionId: '',
            status: 'ERROR',
            message: error.message
          })
          console.error(errorMsg)
        }
      }

      const llm = this.agents.get(agentId)
      if (!llm) {
        throw new Error(`LLM para agente ${agentId} n√£o inicializado ou API Key inv√°lida`)
      }

      // Construir hist√≥rico da conversa
      const conversationHistory = context.conversationHistory
        .slice(-10) // √öltimas 10 mensagens
        .map(msg => `${msg.isFromClient ? 'Cliente' : 'Atendente'}: ${msg.content}`)
        .join('\n')

      // Criar prompt contextualizado incluindo execu√ß√£o de tools
      let systemPrompt = this.buildSystemPrompt(
        agentConfig,
        context,
        conversationHistory
      )

      // Adicionar contexto de tools executadas
      if (toolResults.length > 0) {
        systemPrompt += `\n\nA√á√ïES EXECUTADAS AUTOMATICAMENTE:\n${toolResults.join('\n')}\n\nCONSIDERE ESSAS A√á√ïES NA SUA RESPOSTA AO CLIENTE.`
      }

      // Processar mensagem
      const messages = [
        new SystemMessage(systemPrompt),
        new HumanMessage(message)
      ]

      const response = await llm.invoke(messages)
      let responseText = response.content as string

      // Incluir informa√ß√µes sobre tools na resposta se foram executadas
      if (toolResults.length > 0) {
        responseText += `\n\n${toolResults.join('\n')}`
      }

      // Analisar se deve transferir para outro agente
      const transferAnalysis = await this.analyzeTransferNeed(
        agentConfig,
        message,
        responseText
      )

      // Sugerir tags baseadas no conte√∫do
      const suggestedTags = await this.suggestTags(
        agentConfig.officeId,
        message,
        responseText
      )

      return {
        response: responseText,
        shouldTransfer: transferAnalysis.shouldTransfer,
        suggestedAgent: transferAnalysis.suggestedAgent,
        suggestedTags,
        provider: agentConfig.provider,
        model: agentConfig.aiModel,
        toolExecutions: toolExecutions.length > 0 ? toolExecutions : undefined
      }

    } catch (error) {
      console.error("‚ùå Erro ao processar mensagem:", error)
      return {
        response: "Pe√ßo desculpas, mas ocorreu um erro interno. Um atendente humano entrar√° em contato em breve.",
        shouldTransfer: true,
        suggestedTags: [],
        provider: AIProvider.OPENAI, // fallback
        model: AIModel.GPT_4O_MINI // fallback
      }
    }
  }

  private buildSystemPrompt(
    agentConfig: AgentConfig,
    context: MessageContext,
    conversationHistory: string
  ): string {
    return `${agentConfig.prompt}

CONTEXTO ATUAL:
- Cliente: ${context.clientName || 'N√£o identificado'}
- Telefone: ${context.clientPhone}
- Especialidade atual: ${context.currentSpecialty || 'N√£o definida'}
- Modelo IA: ${agentConfig.provider} ${MODEL_MAPPING[agentConfig.aiModel]}

HIST√ìRICO DA CONVERSA:
${conversationHistory || 'Primeira intera√ß√£o'}

INSTRU√á√ïES ESPEC√çFICAS:
1. Seja sempre cordial, emp√°tico e profissional
2. Use linguagem acess√≠vel, evite jarg√µes jur√≠dicos excessivos
3. Se n√£o souber algo espec√≠fico, seja honesto e ofere√ßa encaminhar para especialista
4. Sempre colete informa√ß√µes importantes sobre o caso
5. Se identificar que o caso n√£o √© da sua especialidade, sugira transfer√™ncia
6. Mantenha respostas objetivas mas humanizadas
7. Sempre termine oferecendo pr√≥ximos passos ou perguntando se h√° d√∫vidas

RESPONDA APENAS COM O TEXTO DA RESPOSTA AO CLIENTE, SEM METADADOS OU INSTRU√á√ïES.`
  }

  private async analyzeTransferNeed(
    agentConfig: AgentConfig,
    clientMessage: string,
    _agentResponse: string // eslint-disable-line @typescript-eslint/no-unused-vars
  ): Promise<{
    shouldTransfer: boolean
    suggestedAgent?: AgentType
  }> {
    // L√≥gica simplificada - pode ser expandida com ML mais avan√ßado
    const message = clientMessage.toLowerCase()
    
    // Palavras-chave por especialidade
    const keywords = {
      [AgentType.BPC_LOAS]: [
        'bpc', 'loas', 'benef√≠cio continuado', 'defici√™ncia', 'idoso 65',
        'baixa renda', 'assistencial'
      ],
      [AgentType.PREVIDENCIARIO]: [
        'aposentadoria', 'inss', 'previd√™ncia', 'benef√≠cio', 'aux√≠lio doen√ßa',
        'pens√£o morte', 'revis√£o', 'contribui√ß√£o'
      ],
      [AgentType.TRABALHISTA]: [
        'trabalho', 'emprego', 'demiss√£o', 'rescis√£o', 'hora extra',
        'ass√©dio', 'acidente trabalho', 'fgts', 'trabalhista'
      ]
    }

    // Se agente atual n√£o √© especialista na √°rea mencionada
    for (const [agentType, keywordList] of Object.entries(keywords)) {
      if (agentType !== agentConfig.type) {
        const hasKeywords = keywordList.some(keyword => 
          message.includes(keyword)
        )
        
        if (hasKeywords) {
          return {
            shouldTransfer: true,
            suggestedAgent: agentType as AgentType
          }
        }
      }
    }

    return { shouldTransfer: false }
  }

  private async suggestTags(
    officeId: string,
    clientMessage: string,
    _agentResponse: string // eslint-disable-line @typescript-eslint/no-unused-vars
  ): Promise<string[]> {
    try {
      // Buscar tags dispon√≠veis para o escrit√≥rio
      const availableTags = await prisma.tag.findMany({
        where: { officeId, isActive: true }
      })

      const message = clientMessage.toLowerCase()
      const suggestedTags: string[] = []

      // Mapear palavras-chave para tags
      const tagKeywords: Record<string, string[]> = {
        'Urgente': ['urgente', 'emerg√™ncia', 'r√°pido', 'pressa'],
        'BPC/LOAS Idoso': ['bpc', 'loas', 'idoso', '65 anos'],
        'BPC/LOAS Deficiente': ['bpc', 'loas', 'defici√™ncia', 'deficiente'],
        'Aposentadoria': ['aposentadoria', 'aposentar'],
        'Aux√≠lio-Doen√ßa': ['aux√≠lio doen√ßa', 'afastamento', 'doente'],
        'Pens√£o por Morte': ['pens√£o', 'morte', '√≥bito', 'falecimento'],
        'Trabalhista': ['trabalho', 'emprego', 'demiss√£o'],
        'Documenta√ß√£o Pendente': ['documento', 'documenta√ß√£o', 'papel', 'comprovante']
      }

      // Verificar quais tags fazem sentido
      for (const tag of availableTags) {
        const keywords = tagKeywords[tag.name] || []
        const hasKeywords = keywords.some(keyword => message.includes(keyword))
        
        if (hasKeywords && !suggestedTags.includes(tag.name)) {
          suggestedTags.push(tag.name)
        }
      }

      return suggestedTags.slice(0, 3) // M√°ximo 3 tags
    } catch (error) {
      console.error("‚ùå Erro ao sugerir tags:", error)
      return []
    }
  }

  async getAvailableAgents(officeId: string): Promise<AgentConfig[]> {
    try {
      const agents = await prisma.aiAgent.findMany({
        where: { officeId, isActive: true },
        include: { office: true }
      })

      return agents.map(agent => ({
        id: agent.id,
        name: agent.name,
        type: agent.type,
        prompt: agent.prompt,
        temperature: agent.temperature,
        maxTokens: agent.maxTokens,
        provider: agent.provider,
        aiModel: agent.aiModel,
        model: MODEL_MAPPING[agent.aiModel]
      }))
    } catch (error) {
      console.error("‚ùå Erro ao buscar agentes:", error)
      return []
    }
  }

  async getAvailableModels(): Promise<Array<{
    provider: AIProvider
    model: AIModel
    displayName: string
    description: string
  }>> {
    return [
      {
        provider: AIProvider.OPENAI,
        model: AIModel.GPT_4_1_MINI,
        displayName: "GPT-4.1 Mini",
        description: "Modelo eficiente e r√°pido da OpenAI"
      },
      {
        provider: AIProvider.OPENAI,
        model: AIModel.GPT_4O_MINI,
        displayName: "GPT-4o Mini",
        description: "Modelo otimizado da OpenAI"
      },
      {
        provider: AIProvider.OPENAI,
        model: AIModel.GPT_4_5,
        displayName: "GPT-4.5",
        description: "Modelo mais avan√ßado da OpenAI"
      },
      {
        provider: AIProvider.GOOGLE,
        model: AIModel.GEMINI_2_5_PRO,
        displayName: "Gemini 2.5 Pro",
        description: "Modelo avan√ßado do Google"
      },
      {
        provider: AIProvider.ANTHROPIC,
        model: AIModel.CLAUDE_3_7,
        displayName: "Claude 3.7",
        description: "Modelo anal√≠tico da Anthropic"
      },
      {
        provider: AIProvider.ANTHROPIC,
        model: AIModel.CLAUDE_4,
        displayName: "Claude 4",
        description: "Modelo mais recente da Anthropic"
      }
    ]
  }

  async refreshAgents(): Promise<void> {
    this.agents.clear()
    this.providerConfigs.clear()
    await this.initializeAgents()
  }

  async checkProviderHealth(officeId: string): Promise<Record<AIProvider, boolean>> {
    const health: Record<AIProvider, boolean> = {
      [AIProvider.OPENAI]: false,
      [AIProvider.GOOGLE]: false,
      [AIProvider.ANTHROPIC]: false
    }

    try {
      const configs = this.providerConfigs.get(officeId)
      if (!configs) return health

      // Testar cada provider com uma mensagem simples
      for (const [provider, apiKey] of configs.entries()) {
        try {
          const testLLM = this.createProviderLLM(
            provider,
            provider === AIProvider.OPENAI ? AIModel.GPT_4O_MINI :
            provider === AIProvider.GOOGLE ? AIModel.GEMINI_2_5_PRO :
            AIModel.CLAUDE_3_7,
            {
              temperature: 0,
              maxTokens: 10,
              apiKey
            }
          )

          if (testLLM) {
            await testLLM.invoke([new HumanMessage("test")])
            health[provider] = true
          }
        } catch (error: unknown) {
          const errorMessage = error instanceof Error ? error.message : String(error)
          console.warn(`‚ö†Ô∏è Provider ${provider} n√£o est√° funcionando:`, errorMessage)
        }
      }
    } catch (error) {
      console.error("‚ùå Erro ao verificar sa√∫de dos providers:", error)
    }

    return health
  }
}

// Singleton instance
export const multiProviderAIManager = new MultiProviderAIManager() 